// Package services provides business logic orchestration for content management.
package services

import (
	"database/sql"
	"fmt"
	"io"
	"net/url"
	"strings"
	"time"

	"github.com/google/uuid"
	"github.com/kimhsiao/memonexus/backend/internal/db"
	"github.com/kimhsiao/memonexus/backend/internal/errors"
	"github.com/kimhsiao/memonexus/backend/internal/logging"
	"github.com/kimhsiao/memonexus/backend/internal/models"
	"github.com/kimhsiao/memonexus/backend/internal/parser"
	"github.com/kimhsiao/memonexus/backend/internal/parser/storage"
)

// ContentService orchestrates content ingestion, parsing, and storage.
type ContentService struct {
	repo    *db.Repository
	parser  *parser.ParserService
	storage *storage.StorageManager
}

// NewContentService creates a new ContentService.
func NewContentService(database *sql.DB, storageDir string) (*ContentService, error) {
	// Initialize repository
	repo := db.NewRepository(database)

	// Initialize parser service
	parserSvc := parser.NewParserService()
	parserSvc.RegisterExtractor(parser.NewWebExtractor())

	// Initialize storage manager
	store, err := storage.NewStorageManager(storageDir)
	if err != nil {
		logging.ErrorWithCode("Failed to initialize storage", string(errors.ErrInternal), err,
			map[string]interface{}{"storage_dir": storageDir})
		return nil, fmt.Errorf("failed to initialize storage: %w", err)
	}

	return &ContentService{
		repo:    repo,
		parser:  parserSvc,
		storage: store,
	}, nil
}

// CreateFromURL creates a content item from a URL.
// T211: Critical operations logging with correlation ID.
func (s *ContentService) CreateFromURL(sourceURL string) (*models.ContentItem, error) {
	startTime := time.Now()
	correlationID := uuid.New().String()

	logging.Info("Content ingestion started",
		map[string]interface{}{
			"correlation_id": correlationID,
			"url":            sourceURL,
		})

	// Validate URL
	parsedURL, err := url.Parse(sourceURL)
	if err != nil {
		logging.ErrorWithCode("URL validation failed", string(errors.ErrInvalid), err,
			map[string]interface{}{
				"correlation_id": correlationID,
				"url":            sourceURL,
			})
		return nil, fmt.Errorf("invalid URL: %w", err)
	}

	// Parse content from URL
	logging.Info("Fetching and parsing content",
		map[string]interface{}{
			"correlation_id": correlationID,
			"host":           parsedURL.Host,
		})
	result, err := s.parser.ParseURL(sourceURL)
	if err != nil {
		logging.ErrorWithCode("Failed to parse URL", string(errors.ErrContentInvalid), err,
			map[string]interface{}{
				"correlation_id": correlationID,
				"url":            sourceURL,
			})
		return nil, fmt.Errorf("failed to parse URL: %w", err)
	}

	logging.Info("Content parsed successfully",
		map[string]interface{}{
			"correlation_id": correlationID,
			"title":          result.Title,
			"word_count":     result.WordCount,
			"media_type":     result.MediaType,
		})

	// Check for duplicate content using SHA-256 hash
	var contentHash string
	if result.ContentText != "" {
		var err error
		contentHash, err = storage.CalculateHash(strings.NewReader(result.ContentText))
		if err != nil {
			logging.ErrorWithCode("Hash calculation failed", string(errors.ErrInternal), err,
				map[string]interface{}{
					"correlation_id": correlationID,
					"url":            sourceURL,
				})
			return nil, fmt.Errorf("failed to calculate hash: %w", err)
		}

		logging.Debug("Content hash calculated",
			map[string]interface{}{
				"correlation_id": correlationID,
				"hash_prefix":    contentHash[:12],
			})

		// Check if content already exists (duplicate detection)
		existing, err := s.findByContentHash(contentHash)
		if err == nil && existing != nil {
			logging.Warn("Duplicate content detected",
				map[string]interface{}{
					"correlation_id": correlationID,
					"existing_id":    existing.ID,
					"created_at":     existing.CreatedAt,
				})
			return existing, fmt.Errorf("duplicate content: already exists as item %s", existing.ID)
		}
	}

	// Create content item
	item := &models.ContentItem{
		Title:       result.Title,
		ContentText: result.ContentText,
		SourceURL:   sourceURL,
		MediaType:   string(result.MediaType),
		Tags:        strings.Join(result.Tags, ","),
		Summary:     "", // Will be generated by analysis service
		ContentHash: contentHash,
	}

	if err := s.repo.CreateContentItem(item); err != nil {
		logging.ErrorWithCode("Failed to create content item", string(errors.ErrDatabase), err,
			map[string]interface{}{
				"correlation_id": correlationID,
				"title":          result.Title,
			})
		return nil, fmt.Errorf("failed to create content item: %w", err)
	}

	duration := time.Since(startTime)
	logging.Info("Content ingestion completed successfully",
		map[string]interface{}{
			"correlation_id": correlationID,
			"id":             item.ID,
			"title":          item.Title,
			"duration_ms":    duration.Milliseconds(),
		})

	return item, nil
}

// CreateFromFile creates a content item from a file upload.
// T211: Critical operations logging with correlation ID.
func (s *ContentService) CreateFromFile(filename string, reader io.Reader) (*models.ContentItem, error) {
	startTime := time.Now()
	correlationID := uuid.New().String()

	logging.Info("File ingestion started",
		map[string]interface{}{
			"correlation_id": correlationID,
			"filename":       filename,
		})

	// Store file in content-addressed storage
	contentHash, size, err := s.storage.StoreFile(reader)
	if err != nil {
		logging.ErrorWithCode("Failed to store file", string(errors.ErrInternal), err,
			map[string]interface{}{
				"correlation_id": correlationID,
				"filename":       filename,
			})
		return nil, fmt.Errorf("failed to store file: %w", err)
	}

	logging.Info("File stored successfully",
		map[string]interface{}{
			"correlation_id": correlationID,
			"hash_prefix":    contentHash[:12],
			"size_bytes":     size,
		})

	// Check for duplicate file (same content hash)
	existing, err := s.findByContentHash(contentHash)
	if err == nil && existing != nil {
		logging.Warn("Duplicate file detected",
			map[string]interface{}{
				"correlation_id": correlationID,
				"existing_id":    existing.ID,
				"existing_title": existing.Title,
			})
		return existing, fmt.Errorf("duplicate file: already exists as item %s", existing.ID)
	}

	// Detect media type from filename
	mediaType := s.detectMediaTypeFromPath(filename)
	logging.Debug("Detected media type",
		map[string]interface{}{
			"correlation_id": correlationID,
			"filename":       filename,
			"media_type":     mediaType,
		})

	// Create content item
	item := &models.ContentItem{
		Title:       filename,
		ContentText: fmt.Sprintf("File: %s (Size: %d bytes)", filename, size),
		SourceURL:   "", // Local file
		MediaType:   string(mediaType),
		Tags:        "",
		ContentHash: contentHash,
	}

	if err := s.repo.CreateContentItem(item); err != nil {
		logging.ErrorWithCode("Failed to create content item", string(errors.ErrDatabase), err,
			map[string]interface{}{
				"correlation_id": correlationID,
				"filename":       filename,
			})
		return nil, fmt.Errorf("failed to create content item: %w", err)
	}

	duration := time.Since(startTime)
	logging.Info("File ingestion completed successfully",
		map[string]interface{}{
			"correlation_id": correlationID,
			"id":             item.ID,
			"filename":       filename,
			"duration_ms":    duration.Milliseconds(),
		})

	return item, nil
}

// GetContent retrieves a content item by ID.
func (s *ContentService) GetContent(id string) (*models.ContentItem, error) {
	return s.repo.GetContentItem(id)
}

// ListContent lists content items with pagination and filters.
func (s *ContentService) ListContent(limit, offset int, mediaType string) ([]*models.ContentItem, error) {
	return s.repo.ListContentItems(limit, offset, mediaType)
}

// UpdateContent updates an existing content item.
func (s *ContentService) UpdateContent(item *models.ContentItem) error {
	return s.repo.UpdateContentItem(item)
}

// DeleteContent soft deletes a content item.
func (s *ContentService) DeleteContent(id string) error {
	return s.repo.DeleteContentItem(id)
}

// SearchContent searches for content items using FTS5.
func (s *ContentService) SearchContent(query string, limit int) ([]*models.ContentItem, error) {
	// TODO: Implement FTS5 search
	// This is a placeholder that returns all items
	return s.repo.ListContentItems(limit, 0, "")
}

// findByContentHash finds a content item by its content hash.
// This implements duplicate detection using SHA-256 hash comparison.
func (s *ContentService) findByContentHash(contentHash string) (*models.ContentItem, error) {
	// Query the database for existing content with the same hash
	items, err := s.repo.ListContentItems(1000, 0, "") // Get recent items for duplicate check
	if err != nil {
		return nil, err
	}

	// Search for matching content hash
	for _, item := range items {
		if item.ContentHash == contentHash {
			logging.Debug("Found duplicate by hash",
				map[string]interface{}{
					"hash_prefix": contentHash[:12],
					"existing_id": item.ID,
				})
			return item, nil
		}
	}

	// No duplicate found
	return nil, sql.ErrNoRows
}

// detectMediaTypeFromPath detects media type from file path extension.
func (s *ContentService) detectMediaTypeFromPath(path string) parser.MediaType {
	dotIdx := strings.LastIndex(path, ".")
	if dotIdx < 0 {
		return parser.MediaTypeWeb
	}

	ext := strings.ToLower(path[dotIdx:])

	switch ext {
	case ".jpg", ".jpeg", ".png", ".gif", ".webp":
		return parser.MediaTypeImage
	case ".mp4", ".webm", ".mov", ".avi":
		return parser.MediaTypeVideo
	case ".pdf":
		return parser.MediaTypePDF
	case ".md", ".markdown":
		return parser.MediaTypeMarkdown
	default:
		return parser.MediaTypeWeb
	}
}

// GetStorageFilePath returns the file system path for a stored media file.
func (s *ContentService) GetStorageFilePath(contentHash string) (string, error) {
	return s.storage.GetFilePath(contentHash)
}

// GetStorageStats returns storage statistics.
func (s *ContentService) GetStorageStats() (*storage.StorageStats, error) {
	return s.storage.GetStats()
}
